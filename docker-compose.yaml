services:

 # backend-api:
   # build:
   #   context: ./api
   #   dockerfile: dockerfile
   # ports:
   #   - "8080:8080"
   #  depends_on:
     # - ollama-server

  qdrant-db:
    image: qdrant/qdrant:v1.13.6
    container_name: qdrant
    restart: unless-stopped
    volumes:
      - ./docker_data/qdrant_data:/qdrant/storage
    ports:
      - "6334:6334"
      - "6333:6333"
    environment:
      QDRANT__LOG_LEVEL: "INFO"

  ollama-server:
    image: ollama/ollama:0.6.5
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      # If you want to set GPU or other config
      # OLLAMA_CUDA: "1"
      OLLAMA_MODEL: "gemma3:4b,nomic-embed-text:latest,gemma3:27b"
    volumes:
      - ./docker_data/ollama_models:/root/.ollama
      - ./docker/ollama-entrypoint.sh:/entrypoint.sh
      - ./docker/zscaler.crt:/zscaler/zscaler.crt
    entrypoint: ["./entrypoint.sh"]
    deploy:
      resources:
        limits:
          memory: 32G
        reservations:
          memory: 32G
